
# Detecting Fake News Using Machine Learning
Collaborators: 
[Samrat Dutta](https://github.com/SamratDuttaOfficial),
[Sagar Biswas](https://github.com/mr-sagar-biswas), 
[Tithi Makar](https://github.com/Tithimakar)


Fake news is an emerging field of research that attracts much attention from academic communities as well as mass media practitioners. The present model aims to detect fake news with the help of Supervised classification Machine Learning algorithm.

## Abstract

Recently, fake news has been incurring many problems to our society. As a result, many researchers have been working on identifying fake news. Most of the fake news detection systems utilize the linguistic feature of the news. However, they have difficulty in sensing highly ambiguous fake news which can be detected only after identifying meaning and latest related information. In this model, to resolve this problem, we shall present a new fake news detection system using  naive Bayes and Natural Language toolkit. 

## Authors

- [Samrat Dutta](https://github.com/SamratDuttaOfficial)
- [Sagar Biswas](https://github.com/mr-sagar-biswas)
- [Tithi Makar](https://github.com/Tithimakar)

## Technology

- **Natural Language Toolkit:** 
The Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language. It was developed by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania. NLTK includes graphical demonstrations and sample data. It is accompanied by a book that explains the underlying concepts behind the language processing tasks supported by the toolkit, plus a cookbook.

- **Naive Bayes:** Naive Bayes is a simple technique for constructing classifiers: models that assign class labels to problem instances, represented as vectors of feature values, where the class labels are drawn from some finite set. There is not a single algorithm for training such classifiers, but a family of algorithms based on a common principle: all naive Bayes classifiers assume that the value of a particular feature is independent of the value of any other feature, given the class variable. For example, a fruit may be considered to be an apple if it is red, round, and about 10 cm in diameter. A naive Bayes classifier considers each of these features to contribute independently to the probability that this fruit is an apple, regardless of any possible correlations between the color, roundness, and diameter features.
In many practical applications, parameter estimation for naive Bayes models uses the method of maximum likelihood; in other words, one can work with the naive Bayes model without accepting Bayesian probability or using any Bayesian methods.
An advantage of naive Bayes is that it only requires a small number of training data to estimate the parameters necessary for classification.

## Original dataset
We have used the data from https://www.uvic.ca/ecs/ece/isot/datasets/fake-news/index.php

In this data there are four columns: 1. Title 2. Text 3. Subject 4. Date
We are using the text content of the news articles to train the machine learning model to judge whether an article is Real or Fake. 

## Process
We executed the experiment in the below process:
1. Data pre-processing
2. Building The machine learning Model.
3. Training the machine learning model
4. Classification.

In this process we have used Python programming language.


## Requirements and Installation
- [NLTK](https://www.tensorflow.org/install/)
- [scikit-learn](https://scikit-learn.org/stable/)
- [matplotlib](https://matplotlib.org/)
- [Pandas](https://pandas.pydata.org/)


## ðŸš€ GitHub
Please visit the Github repository to download and see this project.

https://github.com/SamratDuttaOfficial/TrueAndFakeNews

Pull requests are always welcome.

